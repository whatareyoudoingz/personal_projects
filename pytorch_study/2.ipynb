{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDgX-pYOsUnR",
        "outputId": "ef4316fa-e34e-404f-f3d0-c1e830132415"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSjpvTkdFfOK",
        "outputId": "0bd82491-bff8-425a-8792-330fdb6c2df4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting icrawler\n",
            "  Downloading icrawler-0.6.7-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from icrawler) (6.0.1)\n",
            "Installing collected packages: icrawler\n",
            "Successfully installed icrawler-0.6.7\n"
          ]
        }
      ],
      "source": [
        "!pip install icrawler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4d89-udjFZC9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "from multiprocessing import Pool\n",
        "from icrawler.builtin import GoogleImageCrawler\n",
        "import glob\n",
        "import torch\n",
        "from torch import nn,optim\n",
        "from torch.nn import functional as F\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms,models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDXS_pE4FlD2",
        "outputId": "8d01b37f-d0b3-4c6a-ec15-caf06cc4b781"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device=(\n",
        "    'cuda'\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else 'cpu'\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkmSR57mEvzA"
      },
      "source": [
        "# VGG16 - 재활용 쓰레기 3중 분류 PyTorch 프로그래밍 코드 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTwAwokCFquF"
      },
      "source": [
        "## 데이터 크롤링 및 수집"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjOKOma_DYcJ",
        "outputId": "d9d434af-d86e-431d-e0b1-2f9f9e5f86ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/d/db/Plastic_Carrier_Bags.png\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/Plastic_bag_trashcan_Paris_Vigipirate_dsc00718.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/2/24/Human_cremains_in_plastic_bag.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/b/b1/TWN_Muji_paper_bags_20060731.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/a/aa/India_-_Varanasi_paper_bag_maker_-_0078.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/5/5e/Awfully_Chocolate_bag_-_02.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/6/6e/Brown_paper_bag_texture.jpg\n",
            "ERROR:downloader:Response status code 404, file https://en.wikipedia.org/wiki/File:Homemade_Kr%25C3%25A4ppelchen_in_a_paper_bag.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/Paper_Wise_paper_bag_%282019%29_02.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/5/50/Paper_bag_mask_with_4chan_smiley_at_Anon_raid.jpg\n",
            "ERROR:downloader:Response status code 404, file https://www.flickr.com/photos/visualarts/422903905/\",\"paperbag20070315e.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/4/49/Empty_plastic_bottle.png\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/d/db/Plastic_Carrier_Bags.png\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/Plastic_bag_trashcan_Paris_Vigipirate_dsc00718.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/2/24/Human_cremains_in_plastic_bag.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/b/b1/TWN_Muji_paper_bags_20060731.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/a/aa/India_-_Varanasi_paper_bag_maker_-_0078.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/5/5e/Awfully_Chocolate_bag_-_02.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/6/6e/Brown_paper_bag_texture.jpg\n",
            "ERROR:downloader:Response status code 404, file https://en.wikipedia.org/wiki/File:Homemade_Kr%25C3%25A4ppelchen_in_a_paper_bag.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/Paper_Wise_paper_bag_%282019%29_02.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/5/50/Paper_bag_mask_with_4chan_smiley_at_Anon_raid.jpg\n",
            "ERROR:downloader:Response status code 404, file https://www.flickr.com/photos/visualarts/422903905/\",\"paperbag20070315e.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/5/5b/Crinkled_Wrinkled_Brown_Paper_Bag_Wallpaper_Texture_Free_High_Resolution_Creative_Commons_%288077072070%29.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/4/49/Empty_plastic_bottle.png\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/b/bd/Bales_of_PET_bottles_2.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Bales_of_PET_bottles.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/9/93/Recyclable_finnish_plastic_bottles_with_deposit.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Lidl_%E2%82%AC_0%2C25_Statiegeld_PET_bottle%2C_Winschoten_%282019%29_01.jpg\n",
            "ERROR:downloader:Response status code 404, file https://commons.wikimedia.org/wiki/File:Lidl_%25E2%2582%25AC_0,25_Statiegeld_PET_bottle,_Winschoten_(2019)_01.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Bisleri_PET_water_bottles_with_Telugu_labels.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/d/db/Plastic_Carrier_Bags.png\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Nyaope_plastic_bag_after_being_used.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/b/b1/TWN_Muji_paper_bags_20060731.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/a/aa/India_-_Varanasi_paper_bag_maker_-_0078.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/5/5e/Awfully_Chocolate_bag_-_02.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/6/6e/Brown_paper_bag_texture.jpg\n",
            "ERROR:downloader:Response status code 404, file https://en.wikipedia.org/wiki/File:Homemade_Kr%25C3%25A4ppelchen_in_a_paper_bag.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/Paper_Wise_paper_bag_%282019%29_02.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/5/50/Paper_bag_mask_with_4chan_smiley_at_Anon_raid.jpg\n",
            "ERROR:downloader:Response status code 404, file https://www.flickr.com/photos/visualarts/422903905/\",\"paperbag20070315e.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/4/49/Empty_plastic_bottle.png\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Bales_of_PET_bottles.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/9/93/Recyclable_finnish_plastic_bottles_with_deposit.jpg\n"
          ]
        }
      ],
      "source": [
        "os.mkdir('/content/drive/MyDrive/tensorflow/recycle/')\n",
        "keywords=['plastic bag','paper bag','pet bottle']\n",
        "for x in ['train_data','valid_data','test_data']:\n",
        "  path='/content/drive/MyDrive/tensorflow/recycle/'+x\n",
        "  os.mkdir(path)\n",
        "  for i in keywords:\n",
        "    # 폴더 안에 이미지 삽입\n",
        "    path1=path+'/'+i\n",
        "    os.mkdir(path1)\n",
        "    google_crawler = GoogleImageCrawler(\n",
        "        feeder_threads=1,\n",
        "        parser_threads=1,\n",
        "        downloader_threads=4,\n",
        "        storage={'root_dir': path1 })\n",
        "    filters = dict(\n",
        "        size='large',\n",
        "        license='commercial,modify',\n",
        "        date=((2020, 11, 30), (2023, 10, 30)))\n",
        "    google_crawler.crawl(keyword=i, filters=filters, offset=0, max_num=50,\n",
        "                        min_size=(10,50), max_size=None, file_idx_offset=0)\n",
        "    path2=path1+'/*'\n",
        "    image=glob.glob(path2)\n",
        "    for x,y in enumerate(image):\n",
        "      os.rename(y,os.path.join(path1+\"/\",f\"{i}_\"+\"{0:06d}\".format(x+1)+\".\"+y[-3:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ml-Xxny_NybG"
      },
      "source": [
        "### 데이터 재작업"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNSa3aLOFoFw",
        "outputId": "2948db07-f218-4e9a-954e-6efcc529621c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/d/db/Plastic_Carrier_Bags.png\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/Plastic_bag_trashcan_Paris_Vigipirate_dsc00718.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/2/24/Human_cremains_in_plastic_bag.jpg\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "An error occurred while processing keyword 'paper bag' in iteration 49: list index out of range\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/d/db/Plastic_Carrier_Bags.png\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/Plastic_bag_trashcan_Paris_Vigipirate_dsc00718.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/2/24/Human_cremains_in_plastic_bag.jpg\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "An error occurred while processing keyword 'paper bag' in iteration 49: list index out of range\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/d/db/Plastic_Carrier_Bags.png\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/Plastic_bag_trashcan_Paris_Vigipirate_dsc00718.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/2/24/Human_cremains_in_plastic_bag.jpg\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "An error occurred while processing keyword 'paper bag' in iteration 49: list index out of range\n"
          ]
        }
      ],
      "source": [
        "os.mkdir('/content/drive/MyDrive/tensorflow/recycle/')\n",
        "keywords=['plastic bag','paper bag','pet bottle']\n",
        "data_file=['train_data','valid_data','test_data']\n",
        "day_list=[2017,2019,2021,2023]\n",
        "for x in range(3):\n",
        "  path='/content/drive/MyDrive/tensorflow/recycle/'+data_file[x]\n",
        "  os.mkdir(path)\n",
        "\n",
        "  try:\n",
        "    for i in keywords:\n",
        "      # 폴더 안에 이미지 삽입\n",
        "      path1=path+'/'+i\n",
        "      os.mkdir(path1)\n",
        "      google_crawler = GoogleImageCrawler(\n",
        "          feeder_threads=1,\n",
        "          parser_threads=1,\n",
        "          downloader_threads=4,\n",
        "          storage={'root_dir': path1 })\n",
        "      filters = dict(\n",
        "          size='large',\n",
        "          license='commercial,modify',\n",
        "          date=((day_list[x], 11, 30), (day_list[x+1], 10, 30)))\n",
        "      google_crawler.crawl(keyword=i, filters=filters, offset=0, max_num=50,\n",
        "                          min_size=(10,50), max_size=None, file_idx_offset=0)\n",
        "      path2=path1+'/*'\n",
        "      image=glob.glob(path2)\n",
        "      for x,y in enumerate(image):\n",
        "        os.rename(y,os.path.join(path1+\"/\",f\"{i}_\"+\"{0:06d}\".format(x+1)+\".\"+y[-3:]))\n",
        "  except Exception as e:\n",
        "      print(f\"An error occurred while processing keyword '{i}' in iteration {x}: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPrjUGE_PoqY"
      },
      "source": [
        "#### 에러 : paper bag에서 오류남. => 따로 코드 작성 중"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "599g9PDDFvZR"
      },
      "outputs": [],
      "source": [
        "os.mkdir('/content/drive/MyDrive/tensorflow/recycle/')\n",
        "keywords=['plastic bag','paper bag','pet bottle']\n",
        "data_file=['train_data','valid_data','test_data']\n",
        "day_list=[2017,2019,2021,2023]\n",
        "for x in range(3):\n",
        "  path='/content/drive/MyDrive/tensorflow/recycle/'+'paper bag'\n",
        "  os.mkdir(path)\n",
        "\n",
        "  try:\n",
        "    for i in keywords:\n",
        "      # 폴더 안에 이미지 삽입\n",
        "      path1=path+'/'+i\n",
        "      os.mkdir(path1)\n",
        "      google_crawler = GoogleImageCrawler(\n",
        "          feeder_threads=1,\n",
        "          parser_threads=1,\n",
        "          downloader_threads=4,\n",
        "          storage={'root_dir': path1 })\n",
        "      filters = dict(\n",
        "          size='large',\n",
        "          license='commercial,modify',\n",
        "          date=((day_list[x], 11, 30), (day_list[x+1], 10, 30)))\n",
        "      google_crawler.crawl(keyword=i, filters=filters, offset=0, max_num=50,\n",
        "                          min_size=(10,50), max_size=None, file_idx_offset=0)\n",
        "      path2=path1+'/*'\n",
        "      image=glob.glob(path2)\n",
        "      for x,y in enumerate(image):\n",
        "        os.rename(y,os.path.join(path1+\"/\",f\"{i}_\"+\"{0:06d}\".format(x+1)+\".\"+y[-3:]))\n",
        "  except Exception as e:\n",
        "      print(f\"An error occurred while processing keyword '{i}' in iteration {x}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6bUsHL7Demy",
        "outputId": "dbc09498-249d-4661-e036-0f784395177d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:05<00:00, 105MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "acc@1 : 22.66%\n",
            "acc@1 : 46.09%\n",
            "acc@1 : 70.31%\n",
            "acc@1 : 91.41%\n",
            "Saved the model weights\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "#하이퍼파라미터 설정\n",
        "hyperparams={\n",
        "    \"batch_size\":32,\"learning_rate\":0.0001,\"epochs\":100,\n",
        "    \"transform\":transforms.Compose([\n",
        "        transforms.RandomRotation(degrees=36,expand=False,center=None), #degrees: 각도, expand: 확장여부(True=여백 생성X), center:중심점(None=왼쪽 상단기준)\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomVerticalFlip(p=0.5),\n",
        "        transforms.Resize(256), #크기변환\n",
        "        transforms.CenterCrop(224),#중앙자르기\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize( #정규화\n",
        "            mean=[0.48235,0.45882,0.40784],std=[1.0/255.0,1.0/255.0,1.0/255.0]\n",
        "        )\n",
        "    ])\n",
        "}\n",
        "\n",
        "#데이터 로드 및 변환\n",
        "train_dataset=ImageFolder(\"/content/drive/MyDrive/tensorflow/recycle/train_data\",transform=hyperparams['transform'])\n",
        "test_dataset=ImageFolder(\"/content/drive/MyDrive/tensorflow/recycle/test_data\",transform=hyperparams['transform'])\n",
        "train_dataloader=DataLoader(\n",
        "    train_dataset,batch_size=hyperparams['batch_size'],shuffle=True, drop_last=True\n",
        ")\n",
        "test_dataloader=DataLoader(\n",
        "    test_dataset,batch_size=hyperparams['batch_size'],shuffle=True, drop_last=True\n",
        ")\n",
        "\n",
        "#모델 불러오기\n",
        "model=torchvision.models.vgg16(\n",
        "    weights=\"VGG16_Weights.IMAGENET1K_V1\"\n",
        ")\n",
        "\n",
        "#미세조정 #1000개 분류 => 2개 분류 크기 축소\n",
        "model.classifier[6]=nn.Linear(4096,len(train_dataset.classes))\n",
        "\n",
        "# gpu로 전환\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model=model.to(device)\n",
        "criterion=nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "#옵티마이저 설정\n",
        "optimizer=optim.RMSprop(model.parameters(), lr=hyperparams['learning_rate'])\n",
        "\n",
        "#모델 학습\n",
        "for epoch in range(hyperparams['epochs']):\n",
        "  cost=0.0\n",
        "  for images,classes in train_dataloader:\n",
        "      images=images.to(device)\n",
        "      classes=classes.to(device)\n",
        "\n",
        "      output=model(images)\n",
        "      loss=criterion(output,classes)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      cost+=loss\n",
        "\n",
        "  cost=cost/len(train_dataloader)\n",
        "\n",
        "  if (epoch+1 )%1000 == 0 :\n",
        "      print(f\"Epoch:{epoch+1:4d}, Cost:{cost:.3f}\")\n",
        "\n",
        "# 모델 평가 => 지표 : 정확도\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "\n",
        "    accuracy=0.0\n",
        "    for images,classes in test_dataloader:\n",
        "      images=images.to(device)\n",
        "      classes=classes.to(device)\n",
        "\n",
        "      output=model(images)\n",
        "      probs=F.softmax(output,dim=-1)\n",
        "      output_classes=torch.argmax(probs,dim=-1)\n",
        "      accuracy+=int(torch.eq(classes, output_classes).sum()) #옳게 예측한 개수 누적\n",
        "      print(f\"acc@1 : {accuracy/(len(test_dataloader)*hyperparams['batch_size'])*100:.2f}%\")\n",
        "\n",
        "#최고 성능의 가중치 저장\n",
        "torch.save(model.state_dict(),\"/content/drive/MyDrive/tensorflow//VGG161.pt\")\n",
        "print(\"Saved the model weights\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIovYxYZ_yTB"
      },
      "source": [
        "# 객체 탐지 기술\n",
        "- 경계 상자 탐지\n",
        "- 의미론적 분할\n",
        "- 객체 분할"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cR7nIWuBALQ"
      },
      "source": [
        "## Fast R-CNN\n",
        "- 활용 데이터 : MS COCO\n",
        "  - 328000장의 이미지, 2500만 개의 레이블\n",
        "  - 80개의 클래스\n",
        "- 목적 : 개와 고양이 분류"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vj3J_ntBEP9P"
      },
      "source": [
        "### 데이터세트 클래스 선언"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjdeaH9pBEV6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "from pycocotools.coco import COCO\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class COCODataset(Dataset):\n",
        "  def __init__(self,root,train,transform=None):\n",
        "    super().__init__()\n",
        "    directory=\"train\" if train else \"val\"\n",
        "    annotations=os.path.join(root, \"annotations\",f\"{directory}_annotations.json\")\n",
        "\n",
        "    self.coco = COCO(annotations)\n",
        "    self.iamge_path = os.path.join(root, directory)\n",
        "    self.transform = transform\n",
        "\n",
        "    self.categories = self._get_categories()\n",
        "    self.data = self._load_data()\n",
        "\n",
        "  def _get_categories(self):\n",
        "    categories = {0: \"background\"}\n",
        "    for category in self.coco.cats.values():\n",
        "        categories[category[\"id\"]] = category[\"name\"]\n",
        "    return categories\n",
        "\n",
        "  ## 데이터세트 불러오기\n",
        "  def _load_data(self):\n",
        "      data = []\n",
        "      for _id in self.coco.imgs:\n",
        "          file_name = self.coco.loadImgs(_id)[0][\"file_name\"]\n",
        "          image_path = os.path.join(self.iamge_path, file_name)\n",
        "          image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "          boxes = []\n",
        "          labels = []\n",
        "          anns = self.coco.loadAnns(self.coco.getAnnIds(_id))\n",
        "          for ann in anns:\n",
        "              x, y, w, h = ann[\"bbox\"]\n",
        "\n",
        "              boxes.append([x, y, x + w, y + h])\n",
        "              labels.append(ann[\"category_id\"])\n",
        "\n",
        "          target = {\n",
        "          \"image_id\": torch.LongTensor([_id]),\n",
        "              \"boxes\": torch.FloatTensor(boxes),\n",
        "              \"labels\": torch.LongTensor(labels)\n",
        "          }\n",
        "          data.append([image, target])\n",
        "      return data\n",
        "\n",
        "  ## 호출 및 길이 반환 메서드\n",
        "  def __getitem__(self, index):\n",
        "      image, target = self.data[index]\n",
        "      if self.transform:\n",
        "          image = self.transform(image)\n",
        "      return image, target\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HY1whn51ENlL"
      },
      "source": [
        "### 데이터 로더"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IivZvylDVwM",
        "outputId": "571d5601-6308-4f2c-d1a8-c24af6b2911b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=1.16s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.39s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def collator(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.PILToTensor(),\n",
        "        transforms.ConvertImageDtype(dtype=torch.float)\n",
        "    ]\n",
        ")\n",
        "\n",
        "train_dataset = COCODataset(\"./drive/MyDrive/tensorflow/coco\", train=True, transform=transform)\n",
        "test_dataset = COCODataset(\"./drive/MyDrive/tensorflow/coco\", train=False, transform=transform)\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset, batch_size=4, shuffle=True, drop_last=True, collate_fn=collator\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset, batch_size=1, shuffle=True, drop_last=True, collate_fn=collator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgcF9NgsDfg9",
        "outputId": "91e0b19f-93b3-48b6-96e1-4e92b68d255e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:08<00:00, 62.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "# 모델 준비\n",
        "## 백본 및 모델 구조 정의\n",
        "from torchvision import models\n",
        "from torchvision import ops\n",
        "from torchvision.models.detection import rpn\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "\n",
        "\n",
        "backbone = models.vgg16(weights=\"VGG16_Weights.IMAGENET1K_V1\").features\n",
        "backbone.out_channels = 512\n",
        "\n",
        "anchor_generator = rpn.AnchorGenerator(\n",
        "    sizes=((32, 64, 128, 256, 512),),\n",
        "    aspect_ratios=((0.5, 1.0, 2.0),)\n",
        ")\n",
        "roi_pooler = ops.MultiScaleRoIAlign(\n",
        "    featmap_names=[\"0\"],\n",
        "    output_size=(7, 7),\n",
        "    sampling_ratio=2\n",
        ")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = FasterRCNN(\n",
        "    backbone=backbone,\n",
        "    num_classes=3,\n",
        "    rpn_anchor_generator=anchor_generator,\n",
        "    box_roi_pool=roi_pooler\n",
        ").to(device)\n",
        "\n",
        "## 최적화 함수 및 학습률 스케줄러\n",
        "from torch import optim\n",
        "\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = optim.SGD(params, lr=0.001, momentum=0.9, weight_decay=0.0005)\n",
        "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-ifpHyPELBY"
      },
      "source": [
        "# 모델 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnFy2K-PEH39"
      },
      "source": [
        "# 모델 평가\n",
        "## 파일 크기로 인해 실행 결과 미포함."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Faster R-CNN 미세 조정\n",
        "for epoch in range(5):\n",
        "    cost = 0.0\n",
        "    for idx, (images, targets) in enumerate(train_dataloader):\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        cost += losses\n",
        "\n",
        "    lr_scheduler.step()\n",
        "    cost = cost / len(train_dataloader)\n",
        "    print(f\"Epoch : {epoch+1:4d}, Cost : {cost:.3f}\")\n",
        "\n",
        "## 모델 추론 및 시각화\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "\n",
        "\n",
        "def draw_bbox(ax, box, text, color):\n",
        "    ax.add_patch(\n",
        "        plt.Rectangle(\n",
        "            xy=(box[0], box[1]),\n",
        "            width=box[2] - box[0],\n",
        "            height=box[3] - box[1],\n",
        "            fill=False,\n",
        "            edgecolor=color,\n",
        "            linewidth=2,\n",
        "        )\n",
        "    )\n",
        "    ax.annotate(\n",
        "        text=text,\n",
        "        xy=(box[0] - 5, box[1] - 5),\n",
        "        color=color,\n",
        "        weight=\"bold\",\n",
        "        fontsize=13,\n",
        "    )\n",
        "\n",
        "threshold = 0.5\n",
        "categories = test_dataset.categories\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for images, targets in test_dataloader:\n",
        "        images = [image.to(device) for image in images]\n",
        "        outputs = model(images)\n",
        "\n",
        "        boxes = outputs[0][\"boxes\"].to(\"cpu\").numpy()\n",
        "        labels = outputs[0][\"labels\"].to(\"cpu\").numpy()\n",
        "        scores = outputs[0][\"scores\"].to(\"cpu\").numpy()\n",
        "\n",
        "        boxes = boxes[scores >= threshold].astype(np.int32)\n",
        "        labels = labels[scores >= threshold]\n",
        "        scores = scores[scores >= threshold]\n",
        "\n",
        "        fig = plt.figure(figsize=(8, 8))\n",
        "        ax = fig.add_subplot(1, 1, 1)\n",
        "        plt.imshow(to_pil_image(images[0]))\n",
        "\n",
        "        for box, label, score in zip(boxes, labels, scores):\n",
        "            draw_bbox(ax, box, f\"{categories[label]} - {score:.4f}\", \"red\")\n",
        "\n",
        "        tboxes = targets[0][\"boxes\"].numpy()\n",
        "        tlabels = targets[0][\"labels\"].numpy()\n",
        "        for box, label in zip(tboxes, tlabels):\n",
        "            draw_bbox(ax, box, f\"{categories[label]}\", \"blue\")\n",
        "\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Z4DRBRkqEC2q",
        "outputId": "2ac2d3e2-3168-440a-97a5-d73d26b8b768"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading and preparing results...\n",
            "Converting ndarray to lists...\n",
            "(1110, 7)\n",
            "0/1110\n",
            "DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=0.17s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.04s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.262\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.616\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.169\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.039\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.267\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.279\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.320\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.432\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.432\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.045\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.371\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.488\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    coco_detections = []\n",
        "    for images, targets in test_dataloader:\n",
        "        images = [img.to(device) for img in images]\n",
        "        outputs = model(images)\n",
        "\n",
        "        for i in range(len(targets)):\n",
        "            image_id = targets[i][\"image_id\"].data.cpu().numpy().tolist()[0]\n",
        "            boxes = outputs[i][\"boxes\"].data.cpu().numpy()\n",
        "            boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n",
        "            boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n",
        "            scores = outputs[i][\"scores\"].data.cpu().numpy()\n",
        "            labels = outputs[i][\"labels\"].data.cpu().numpy()\n",
        "\n",
        "            for instance_id in range(len(boxes)):\n",
        "                box = boxes[instance_id, :].tolist()\n",
        "                prediction = np.array(\n",
        "                    [\n",
        "                        image_id,\n",
        "                        box[0],\n",
        "                        box[1],\n",
        "                        box[2],\n",
        "                        box[3],\n",
        "                        float(scores[instance_id]),\n",
        "                        int(labels[instance_id]),\n",
        "                    ]\n",
        "                )\n",
        "                coco_detections.append(prediction)\n",
        "\n",
        "    coco_detections = np.asarray(coco_detections)\n",
        "    coco_gt = test_dataloader.dataset.coco\n",
        "    coco_dt = coco_gt.loadRes(coco_detections)\n",
        "    coco_evaluator = COCOeval(coco_gt, coco_dt, iouType=\"bbox\")\n",
        "    coco_evaluator.evaluate()\n",
        "    coco_evaluator.accumulate()\n",
        "    coco_evaluator.summarize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyHBuyfCSytL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Ml-Xxny_NybG",
        "uPrjUGE_PoqY"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
